{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\muril\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muril\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\muril\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in c:\\users\\muril\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\muril\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muril\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\muril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk \n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banco de dados de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/artigos.txt', 'r', encoding=\"utf8\") as f:\n",
    "    artigos = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/br-sem-acentos.txt', 'r', encoding=\"utf8\") as f:\n",
    "    dicio = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "texto_exemplo = 'Olá, tudo bem?'\n",
    "tokens = texto_exemplo.split()\n",
    "print(tokens)\n",
    "# Token é uma sequência de caracteres, separados por um limitador,\n",
    "# que pode ser um espaço em branco, pontuação ou quebra de linhas, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', ',', 'tudo', 'bem', '?']\n"
     ]
    }
   ],
   "source": [
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "print(palavras_separadas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separador de palavras - tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    \n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O numero de palavras é 653351\n"
     ]
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_tokens += nltk.tokenize.word_tokenize(dicio)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f'O numero de palavras é {len(lista_palavras)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando todas as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao (lista_palavras):                          \n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653351"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "len(lista_normalizada)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções do corretor\n",
    "## insere, deleta, troca..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def deletando_letras (fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def trocando_letras (fatias):\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def invertendo_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras (palavra):\n",
    "    \n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):               \n",
    "        fatias.append((palavra[:i], palavra[i:]))   \n",
    "    palavras_geradas = insere_letras(fatias)    \n",
    "    palavras_geradas += deletando_letras(fatias)   \n",
    "    palavras_geradas += trocando_letras(fatias) \n",
    "    palavras_geradas += invertendo_letras(fatias)\n",
    "    \n",
    "    return palavras_geradas\n",
    "\n",
    "def gerador_turbinado(palavra):\n",
    "    novas_palavras = [0]\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(set(lista_normalizada))\n",
    "frequencia.most_common(5)\n",
    "\n",
    "def probabilidade (palavra_gerada):\n",
    "    \n",
    "    return frequencia[palavra_gerada]/total_palavras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista com palavras corretas e erradas para uma avaliação do corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding=\"utf8\")\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close\n",
    "    return lista_palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_teste = cria_dados_teste(\"Data/palavras.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor (palavra):\n",
    "    palavra2 = palavra\n",
    "    candidatos = []\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in palavras_geradas:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "        \n",
    "    if len(candidatos) > 1:\n",
    "        palavra_correta = max(candidatos, key = probabilidade)\n",
    "                \n",
    "    else:        \n",
    "        palavras_geradas2 = gerador_palavras(palavra2)\n",
    "        palavras_turbinado2 = gerador_turbinado(palavra2)\n",
    "        todas_palavras2 = set(palavras_geradas2 + palavras_turbinado2)\n",
    "        candidatos2 = [palavra2]\n",
    "        for palavra2 in todas_palavras2:\n",
    "            if palavra2 in vocabulario:\n",
    "                candidatos2.append(palavra2)\n",
    "           \n",
    "        palavra_correta = max(candidatos2, key = probabilidade)\n",
    "\n",
    "        \n",
    "    return palavra_correta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador (testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "\n",
    "    taxa_acerto = round(acertou / numero_palavras * 100, 2)\n",
    "    taxa_desconhecida = round(desconhecida / numero_palavras * 100, 2)\n",
    "    print(f'{taxa_acerto}% de {numero_palavras}, desconhecidas sao: {taxa_desconhecida}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252528"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulario = set(lista_normalizada)\n",
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.32% de 186, desconhecidas sao: 0.0%\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tomar'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor('tomare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erradas (testes, vocabulario):\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida != correta:\n",
    "            print(errada + '/' + correta + '/' + palavra_corrigida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eme/ele/em\n",
      "noâ/nos/no\n",
      "teb/ter/tem\n",
      "âem/bem/em\n",
      "serr/será/ser\n",
      "eû/eu/e\n",
      "jé/já/é\n",
      "dms/das/dos\n",
      "cava/cada/java\n",
      "nossk/nossa/nosso\n",
      "ìeu/eu/seu\n",
      "qelay/ela/delay\n",
      "deiìa/dia/deixa\n",
      "eúaa/ela/essa\n",
      "dĩaz/dia/da\n",
      "asterístico/asterisco/asterístico\n",
      "tomare/tomara/tomar\n",
      "mindigo/mendigo/indigo\n"
     ]
    }
   ],
   "source": [
    "erradas(lista_teste, vocabulario)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f00a03ebb2da9daceae83481c3c63f1c536cc7cbc8cd2b481abece1ac6c15d93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
